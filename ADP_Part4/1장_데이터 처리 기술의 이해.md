# 1장. 데이터 처리 프로세스
<br/>

## 학습목표
    - ETL, ODS 구성, 데이터 웨어하우스를 이해한다
    - CDC, EAI에 대해 이해한다
    - 데이터 연계 및 통계 기법을 분류하고 각 용도를 이해한다
    - 데이터 통합 및 연계 기법과 빅데이터 처리 기법을 비교한다
    - 대용량의 비정형 데이터 처리방법에 대해 이해한다
<br/>

## 1절. ETL(Extraction, Transformation, Load)
### 1. ETL 개요
#### 가. ETL의 개념 및 특징
    - 다양한 데이터 원천으로부터 데이터를 추출 및 변환하여 운영 데이터 스토어(ODS), 데이터 웨어하우스, 데이터 마트 등에 데이터를 적재하는 작업의 핵심 구성요소
    - MPP(Massive Parallel Processing) 지원
    - Batch ETL, Real Time ETL로 구분
#### 나. ETL의 기능
|||
|:--:|:--|
|Extraction|하나 또는 그 이상의 데이터 원천들로부터 데이터 획득|
|Transformation|데이터 클렌징, 형식 변환, 표준화, 통합 또는 다수 애플리케이션에 내장된 비즈니스 룰 적용 등|
|Loading|변형 단계의 처리가 완료된 데이터를 특정 목표 시스템에 적재|
#### 다. ETL의 작업 단계
|||
|:--:|:--|
|Step0<br>interface|다양한 이기종 DBMS 및 스프레드 시트 등 데이터 원천으로부터 데이터를 획득하기 위한 인터페이스 메커니즘 구현|
|Step1<br>Staging ETL|수립된 일정에 따라 데이터원천으로부터 트랜잭션 데이터 획득 작업 수행 후, 획득된 데이터를 스테이징 테이블에 저장|
|Step2<br>Profiling ETL|스테이징 테이블에서 데이터 특성을 식별하고 품질을 측정|
|Step3<br>Cleansing ETL|다양한 규칙들을 활용해 프로파일링된 데이터의 보정 작업을 수행|
|Step4<br>Integration ETL|(이름, 값, 구조) 데이터 충돌을 해소하고, 클렌징된 데이터를 통합|
|Step5<br>Demoralizing ETL|운영 보고서 생성 및 데이터 웨어하우스 또는 데이터 마트에 대한 데이터 적재를 위해 데이터 비정규화 수행|
<br/>

### 2. ODS 구성
#### 가. ODS의 개념 및 특징
    - 데이터 Cleansing, 데이터 Integration 작업 포함
    - ODS는 Real Time 또는 Near Real Time 트랜잭션 데이터 혹은 개별성을 지닌 하위 수준 데이터들을 저장하기 위해 설계
#### 나. ODS의 구성 단계
##### 1) 인터페이스 단계
##### 2) 데이터 스테이징 단계
##### 3) 데이터 프로파일링 단계
##### 4) 데이터 클렌징 단계
##### 5) 데이터 인테그레이션 단계
##### 6) 익스포트 단계
<br/>

### 3. 데이터웨어하우스
#### 가. 데이터 웨어하우스란?
#### 나. 데이터 웨어하우스의 특징
|||
|:--:|:--|
|주제 중심성|데이터 웨어하우스의 데이터는 실 업무 상황의 특정 이벤트나 업무 항목을 기준으로 구조화되므로, 최종사용자도 이해하기 쉬운 형태를 지닌다.|
|영속성, 비휘발성|데이터 웨어하우스의 데이터는 최초 저장 이후에는 읽기 전용의 속성을 가지며, 삭제되지 않는다.|
|통합성|데이터 웨어하우스의 데이터는 기관, 조직이 보유한 대부분의 운영 시스템들에 의해 생성된 데이터들의 통합본이다|
|시계열성|운영 시스템들은 최신 데이터를 보유하고 있지만, 데이터 웨어하우스는 시간 순에 의한 이력 데이터를 보유한다|
<br/>

#### 다. 데이터 웨어하우스의 테이블 모델링 기법
##### 1) 스타 스키마
    - 데이터 웨어하우스의 스키마 중 가장 단순
    - Fact Table은 보통 제 3정규형으로 모델링
    - Dimensional Table은 제 2정규형으로 모델링
|||
|:--:|:--|
|장점|스노우 플레이크 스키마에 비해 복잡도가 낮아서 이해하기 쉽고, 쿼리 작성이 용이하고 조인 테이블 개수가 적다|
|단점|차원 테이블들의 비정규화에 따른 데이터 중복으로 인해 테이블로 데이터를 적재할 때 상대적으로 많은 시간이 소요된다|
##### 2) 스노우 플레이크 스키마
    - 스타 스키마의 차원 테이블을 제 3정규형으로 정규화한 형태
|||
|:--:|:--|
|장점|데이터의 중복이 제거돼 데이터 적재 시 시간이 단축된다|
|단점|스타 스키마에 비해 스키마 구조의 복잡성이 증가하므로 조인 테이블의 개수가 증가하고 쿼리 작성의 난이도가 상승된다|
<br/>

#### 라. ODS와 DW의 비교
|구분|ODS(Operational Data Store|DW(Data Warehouse|
|:--:|:--:|:--:|
|데이터의 내용|현재 또는 비교적 최신 데이터|오래된 상세 데이터, 현재 상세 데이터, 등|
|데이터의 양|비교적 소규모 데이터|대규모 데이터|
|데이터의 갱신|지속적으로 갱신되어 현재의 DB 상태를 반영(Volatile)|데이터 축적 보관(nonvolatile)|
|기술적 요소|데이터베이스 처리의 모든 기능을 사용하도록 설계|단순한 적재와 접근 중심|
<br/>

## 2절. CDC(Change Data Capture)
### 1. CDC의 개념 및 특성
    - 데이터베이스 내 데이터에 대한 변경을 식별해 필요한 후속처리를 자동화하는 기술 또는 설계 기법이자 구조
### 2. CDC 구현 기법
#### 가. Time Stamp on Rows
#### 나. Version Numbers on Rows
#### 다. Status on Rows
#### 라. TIme/Version/Status on Rows
#### 마. Triggers on Tables
#### 바. Event Programming
#### 사. Log Scanner on Database
    - 장점 : 데이터베이스와 사용 애플리케이션에 대한 영향도 최소화, 변경 식별 지연시간 최소화, 트랜잭션 무결성에 대한 영향도 최소화, 데이터베이스 스키마 변경 불필요
### 3. CDC 구현 방식
|||
|:--:|:--|
|푸시 방식|데이터 원천에서 변경을 식별하고 대상 시스템에 변경 데이터를 적재해 주는 방식|
|풀 방식|대상 시스템에서 데이터 원천을 정기적으로 살펴보고, 필요 시 데이터를 다운로드 하는 방식|
<br/>

## 3절. EAI(Enterprise Application Integration)
### 1. EAI의 개념 및 특징
    - ETL은 배치 프로세스 중심이며, EAI는 실시간 혹은 근접 실시간 처리 중심이다
### 2. 데이터 연계 방식
#### 가. 기존의 데이터 연계 방식 : Point to Point
    - 기준 마스터 데이터의 통합과 표준화가 불가능
    - 복잡한 데이터 연계 경로 발생
    - 유지 보수성이 극도로 저하
#### 나. EAI의 데이터 연계 방식 : Hub and Spoke
    - 허브 역할을 하는 브로커를 둔다
    - ETL/CDC는 운영 데이터와 분석을 위한 데이터베이스가 구분
    - EAI는 다수 정보 시스템의 데이터를 중앙의 Hub가 연계하고 통합하는 기법
    - 각 연결의 대상이 되는 노드들은 Spoke에 해당
### 3. EAI 구성요소
    - 어댑터 : 각 정보 시스템과 EAI 허브간의 연결성을 확보
    - 버스 : 어댑터를 매개로 연결된 각 정보 시스템들 간의 데이터 연동 경로
    - 브로커 : 데이터 연동 규칙을 통제
    - 트랜스포머 : 데이터 형식 변환을 담당
### 4. EAI 구현 유형
#### 가. Mediation(intra-communication)
    - Publish / subscribe Model
#### 나. Federation(inter-communication)
    - Request / reply Model
### 5. EAI 활용 효과
    - 분리되어 있는 정보 시스템들 간의 데이터 동기화
    - 데이터 표준화 기반 제공
### 6. EAI와 ESB의 비교
|구분|EAI(Enterprise Application Integration|ESB(Enterprise Service Bus)|
|:--:|:--:|:--:|
|기능|미들웨어(Hub)를 이용하여 비즈니스 로직을 중심으로 Application을 통합, 연계|미들웨어(Bus)를 이용하여 서비스 중심으로 시스템을 유기적으로 연계|
|통합관점|Application|Process|
|로직연동|개별 Application에서 수행|ESB에서 수행|
|아케텍처|단일 접점인 허브시스템을 이용한 중앙집중식 연결구조|버스(Bus) 형태의 느슨하고 유연한 연결구조|
<br/>

## 4절. 데이터 통합 및 연계 기법
### 1. 데이터 연계 및 통합 유형(동기화 기준)
    - 실시간 통합시에는 관심 대상 영역 상태에 대한 빠른 파악 및 대응이 가능하다는 장점이 있다.
<데이터 연계 및 통합 아키텍처 비교>
|일괄(Batch)통합|비동기식 실시간 통합|동기식 실시간 통합|
|:--|:--|:--|
|- 비실시간 데이터 통합<br/>- 대용량 데이터 대상<br/>- 높은 데이터 조작 복잡성<br/>- ETL<br/>- CDC<br/>- 감사 증적<br/>- 웹서비스/SOA<br/>- 교차 참조<br/>- 데이터 재처리 허용<br/>- 점대점 데이터 연계<br/>- 자동화 도구 및 자체 개발 SW 혼용|- 근접 실시간 데이터 통합<br/>- 중간 용량 데이터<br/>- 중간 데이터 조작 복잡성<br/>- ETL<br/>- CDC<br/>- Data pooling and DB Streams<br/>- 웹서비스/SOA<br/>- 감사 증적<br/>- 교차 참조<br/>- 다수 데이터 원천 및 목표 시스템<br/>- 데이터 재처리 허용<br/>- 자동화 도구 및 자체 개발 SW 혼용|- 실시간 데이터 통합<br/>- 목표 시스템 데이터 처리 가능시에만 원천 데이터 획득<br/>- ETL<br/>- 웹서비스/SOA<br/>- Single transaction integration<br/>- 단일 트랜잭션 단위 데이터 통합<br/>- 데이터 재처리 불가<br/>- 단일 또는 다수 데이터 원천<br/>- 감사 증적|
<br/>

<데이터 처리 기법 비교>
|구분|전통적 데이터 처리 기법|빅데이터 처리 기법|비고|
|:--:|:--:|:--:|:--:|
|추출|- 운영 DB -> ODS<br/>- ODS -> 데이터 웨어하우스|- 빅데이터 환경 -> 빅데이터 환경|특정 소스에서 타깃으로 데이터를 옮긴다는 측면은 동일|
|변환|O|O||
|로딩|O|O||
|시각화|X|O|시각화를 통해 대용량 데이터에서 통찰력을 획득하고자 하는 시도는 빅데이터의 고유한 특성|
|분석|- OLAP<br/>- 통계와 데이터마이닝 기술|- 통계와 데이터마이닝 기술|각종 통계 도구, 기법과 데이터 마이닝의 분석 모델 설계, 운영, 개선 기법의 적용은 유사함|
|리포팅|비즈니스 인텔리전스|비즈니스 인텔리전스||
|인프라스트럭처|- SQL<br/>- 전통적 RDBS 인스턴스|- NoSQL 등<br/>- 초대형 분산 데이터 스토리지|전통적 데이터 저장 메커니즘 대비 다수의 노드에 중복을 허용하는 방식으로 데이터를 저장하는 것은 빅데이터의 고유한 특성임|
<br/>

## 5절. 대용량의 비정형 데이터 처리방법
### 1. 대용량 로그 데이터 수집
#### 가. 로그(log)
    - 아파치 Flume-NG, 페이스북 Scribe, 아파치 Chukwa 등
#### 나. 대용량 비정형 데이터 수집 시스템의 특징
##### 1) 초고속 수집 성능과 확장성
    - 쉽게 확장할 수 있는 구조를 가진다
##### 2) 데이터 전송 보장 메커니즘
    - 분산 파일시스템, DB, NoSQL 등에 저장
    - 데이터 전송 안정성 수준을 제어할 수 있다.
    - 성능과 안정성이라는 트레이드 오프가 존재
##### 3) 다양한 수집과 저장 플러그인
##### 4) 인터페이스 상속을 통한 애플리케이션 기능 확장
### 2. 대규모 분산 병렬 처리
#### 가. 하둡(Hadoop)
    - 맵리듀스시스템과 분산 파일시스템인 HDFS를 핵심 구성 요소로 가지는 플랫폼 기술
    - 여러대의 컴퓨터를 마치 하나의 시스템인 것 처럼 묶은 자바 기반의 오픈소스 프레임워크
    - 비공유 분산 아키텍처를 사용
#### 나. 하둡(Hadoop)의 특징
##### 1) 선형적인 성능과 용량 확장
    - 비공유 분산 아키텍처 시스템 -> 서버를 추가하면 연산 기능과 저장 기능이 서버의 대수에 비례해 증가
##### 2) 고장 감내성
    - 데이터는 3중 복제
    - 맵리듀스 작업 수행 중 특정 테스크에서 장애가 생기면, 시스템이 자동으로 감지해 장애가 발생한 특정 태스크만 다른 서버에서 재실행 할 수 있다.
##### 3) 핵심 비즈니스 로직에 집중
    - 하둡의 맵리듀스는 맵과 리듀스라는 2개의 함수만 구현
##### 4) 풍부한 에코시스템 형성
    - Zookeeper : 분산 환경에서 서버들간에 상호 조정이 필요한 다양한 서비스 제공
    - Oozie : 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템
    - Hbase : HDFS 기반의 컬럼 NoSQL
    - Pig : 복잡한 MapReduce 프로그래밍을 대체할 Pig Latin 언어 제공
    - Hive : 하둡 기반의 데이터웨어하우스, 테이블 단위의 데이터 저장과 SQL 쿼리를 지원
    - Mahout : 하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈 소스 라이브러리
    - Hcatalog : 하둡 기반의 테이블 및 스토리지 관리
    - Avro : RPC(Remote Procedure Call)과 데이터 직렬화를 지원하는 프레임워크
    - Chukwa : 분산 환경에서 생성되는 데이터를 HDFS에 안정적으로 저장시키는 플랫폼
    - Flume : 소스서버에 에이전트가 설치되고, 에이전트로부터 데이터를 전달받는 콜랙터로 구성
    - Scribe : 페이스북에서 개발된 데이터 수집 플랫폼으로 Chukwa와 달리 중앙집중서버로 전송
    - Sqoop : 대용량 데이터 전송 솔루션이며, HDFS, RDBMS, DW, NoSQL 등 다양한 저장소에 대용량 데이터를 신속하게 전송할 수 있는 방법 제공
    - Hiho : Sqoop과 같은 대용량 데이터 전송 솔루션으로 하둡에서 데이터를 가져오기 위한 SQL을 지정할 수 있으며, JDBC 인터페이스를 지원
    - YARN은 맵리듀스의 단점을 극복하기 위해 시작되어 분산 애플리케이션을 구현하기 위한 자원 관리 프레임워크를 지원
    - Flume-NG는 데이터가 발생하는 애플리케이션 단계, 발생한 데이터를 수집하는 단계, 수집한 데이터를 저장하는 단계, 데이터 저장소 보관 단계로 이루어짐
<하둡 에코 시스템의 구성>
|구분|주요기술|구분|주요기술|
|:--:|:--:|:--:|:--:|
|데이터 수집|Flume_NG, kafka|대용량 SQL 질의|Hive, Pig|
|데이터 연동|Sqoop|실시간 SQL 질의|Impala, Tajo|
|분산 데이터베이스|Hbase|워크플로우 관리|Oozie, Azkaban|
<br/>

### 3. 데이터 연동
#### 가. 데이터 연동의 개요
    - 정형 데이터와 분석하고자 하는 비정형 데이터를 연동하는 것이 필요
    - 데이터베이스의 데이터를 하둡으로 복사한 후 하둡에서 대규모 분산 처리를 수행
    - 생성된 작은 요약 데이터셋을 다시 데이터베이스에 기록하는 방식
    - 데이터 연동 기능을 수행하는 대표적인 오픈 소스 솔루션이 스쿱(Sqoop)
#### 나. 스쿱(Sqoop)
    - 하둡과 데이터베이스간의 데이터 연동 솔루션인 스쿱은 대부분의 관계형 데이터베이스와의 연동을 지원
    - Hbase와 같은 일부 NoSQL 데이터베이스와도 연동이 가능
### 4. 대용량 질의 기술
#### 가. 대용량 질의 기술의 개요
    - SQL 질의기술을 이용해 하둡에 저장된 데이터를 쉽게 처리하고 분석할 수 있도록 해주는 '하이브(Hive)가 등장
    - 실시간 조회 및 처리에 대한 제약을 극복하기 위해 실시간 SQL 질의 분석 기술인 SQL on 하둡이 등장
#### 나. SQL on 하둡 기술
    - 아파치 드릴
    - 아파치 스팅거
    - 샤크
    - 아파치 타조 : 고려대 대학원에서 시작된 프로젝트로 국내 빅데이터 전문회사인 그루터가 합류하여 개발을 진행하고 있고, 아파치 인큐베이션 프로젝트로 등록되어 있음
    - 임팔라
    - 호크
    - 프레스토 : 페이스북에서 자체적으로 개발하여 사용하고 있는 하둡 기반의 데이터웨어 하우징엔진, 아파치 라이선스로 공개